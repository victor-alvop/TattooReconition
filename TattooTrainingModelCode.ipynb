{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GfaB8pWp-HP",
        "outputId": "3394a46f-4a61-4f76-831d-2660ad2702bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/MODEL-TRAINING/cruz/catholic-symbols-cross-christian-icons-600nw-2261127533.jpg is not an image\n",
            "/content/drive/MyDrive/MODEL-TRAINING/cruz/tattoo-t-shirt-design-black-600nw-2295350383.jpg is not an image\n",
            "/content/drive/MyDrive/MODEL-TRAINING/cruz/151388517-conjunto-de-ilustraciones-de-cruces-religiosas-cristianas-aladas-elemento-de-diseño-para-infografía.jpg is not an image\n",
            "/content/drive/MyDrive/MODEL-TRAINING/cruz/tattoo-t-shirt-design-black-600nw-2295350383 (1).jpg is not an image\n",
            "/content/drive/MyDrive/MODEL-TRAINING/cruz/christian-cross-vector-icon-symbols-260nw-2353702527.jpg is not an image\n",
            "/content/drive/MyDrive/MODEL-TRAINING/cruz/catholic-symbols-cross-christian-icons-600nw-2261127533 (1).jpg is not an image\n",
            "/content/drive/MyDrive/MODEL-TRAINING/cruz/catholic-symbols-cross-christian-icons-600nw-2261127533 (2).jpg is not an image\n",
            "/content/drive/MyDrive/MODEL-TRAINING/cruz/crown-thorns-wooden-cross-easter-600nw-2201023355.jpg is not an image\n",
            "/content/drive/MyDrive/MODEL-TRAINING/cruz/tattoo-t-shirt-design-black-600nw-2295350383 (2).jpg is not an image\n",
            "/content/drive/MyDrive/MODEL-TRAINING/cruz/solar-cross-icon-vector-illustration-600nw-2256811835.jpg is not an image\n",
            "/content/drive/MyDrive/MODEL-TRAINING/cruz/continuous-line-jesus-christ-drawing-600nw-2212769417.jpg is not an image\n",
            "/content/drive/MyDrive/MODEL-TRAINING/cruz/iron-cross-flat-black-white-600w-2273168479.jpg is not an image\n",
            "/content/drive/MyDrive/MODEL-TRAINING/cruz/215820428-hermosa-cruz-cristiana-gótica-con-paloma-peave-y-vector-de-crucifijo-de-rama-de-olivo-aislado-sobre.jpg is not an image\n",
            "/content/drive/MyDrive/MODEL-TRAINING/cruz/black-white-cartoon-graveyard-cross-260nw-1170585142.jpg is not an image\n",
            "/content/drive/MyDrive/MODEL-TRAINING/cruz/185430313-símbolo-cruzado-dibujado-a-mano-símbolo-de-cruz-de-dibujo-negro-sobre-fondo-blanco-ilustración.jpg is not an image\n"
          ]
        }
      ],
      "source": [
        "# validacion de imagenes\n",
        "# se usa para confirmar que las imagenes tengan el formato correcto\n",
        "\n",
        "from pathlib import Path\n",
        "import imghdr\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/MODEL-TRAINING/cruz\"\n",
        "image_extensions = [\".png\", \".jpg\"]  # imagenes necesarias\n",
        "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
        "\n",
        "for filepath in Path(data_dir).rglob(\"*\"):\n",
        "    if filepath.suffix.lower() in image_extensions:\n",
        "        img_type = imghdr.what(filepath)\n",
        "        if img_type is None:\n",
        "            print(f\"{filepath} is not an image\")\n",
        "        elif img_type not in img_type_accepted_by_tf:\n",
        "            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ytl-b4eAn5S8"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXJWYkc9n9rp",
        "outputId": "ca5d3ebb-48c3-407f-e90c-213bde600de4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2190 files belonging to 3 classes.\n",
            "Using 1752 files for training.\n",
            "Found 2190 files belonging to 3 classes.\n",
            "Using 438 files for validation.\n"
          ]
        }
      ],
      "source": [
        "# Declaracion del dataset\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/drive/MyDrive/MODEL-TRAINING\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32,\n",
        ")\n",
        "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/drive/MyDrive/MODEL-TRAINING\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgixhKUSoUFy",
        "outputId": "affc4389-ac4f-4acc-f9b0-918618550674"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['cruz', 'maori', 'roses']\n"
          ]
        }
      ],
      "source": [
        "# Declaracion de las etiquetas que corresponden a las imágenes\n",
        "class_names = train_dataset.class_names\n",
        "num_classes = len(class_names)\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZPbqWWSoW-a"
      },
      "outputs": [],
      "source": [
        "# Procesamiento de las imágenes y usarlas dentro de la creación del modelo\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.experimental.preprocessing.Rescaling(1.0 / 255),\n",
        "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "        layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwEdPWa3oc5D"
      },
      "outputs": [],
      "source": [
        "# Creación del modelo\n",
        "model = keras.Sequential([\n",
        "    data_augmentation,\n",
        "    layers.Conv2D(32, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(128, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(num_classes)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrAWegO0ofSc",
        "outputId": "16f93fb6-0547-4434-d46f-c167b0529db7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "55/55 [==============================] - 412s 6s/step - loss: 1.2614 - accuracy: 0.5166 - val_loss: 0.9943 - val_accuracy: 0.6233\n",
            "Epoch 2/35\n",
            "55/55 [==============================] - 12s 183ms/step - loss: 0.8163 - accuracy: 0.6433 - val_loss: 0.7348 - val_accuracy: 0.7169\n",
            "Epoch 3/35\n",
            "55/55 [==============================] - 13s 218ms/step - loss: 0.7258 - accuracy: 0.6941 - val_loss: 0.7560 - val_accuracy: 0.7192\n",
            "Epoch 4/35\n",
            "55/55 [==============================] - 10s 168ms/step - loss: 0.6685 - accuracy: 0.7209 - val_loss: 0.7600 - val_accuracy: 0.7420\n",
            "Epoch 5/35\n",
            "55/55 [==============================] - 11s 168ms/step - loss: 0.7544 - accuracy: 0.6844 - val_loss: 0.8909 - val_accuracy: 0.6575\n",
            "Epoch 6/35\n",
            "55/55 [==============================] - 9s 152ms/step - loss: 0.6701 - accuracy: 0.7329 - val_loss: 0.7001 - val_accuracy: 0.7215\n",
            "Epoch 7/35\n",
            "55/55 [==============================] - 12s 187ms/step - loss: 0.6188 - accuracy: 0.7409 - val_loss: 0.7016 - val_accuracy: 0.7237\n",
            "Epoch 8/35\n",
            "55/55 [==============================] - 9s 152ms/step - loss: 0.6133 - accuracy: 0.7500 - val_loss: 0.7033 - val_accuracy: 0.7192\n",
            "Epoch 9/35\n",
            "55/55 [==============================] - 12s 189ms/step - loss: 0.5684 - accuracy: 0.7671 - val_loss: 0.7734 - val_accuracy: 0.7100\n",
            "Epoch 10/35\n",
            "55/55 [==============================] - 12s 193ms/step - loss: 0.5294 - accuracy: 0.7831 - val_loss: 0.6677 - val_accuracy: 0.7603\n",
            "Epoch 11/35\n",
            "55/55 [==============================] - 9s 152ms/step - loss: 0.5316 - accuracy: 0.7820 - val_loss: 0.6633 - val_accuracy: 0.7306\n",
            "Epoch 12/35\n",
            "55/55 [==============================] - 12s 190ms/step - loss: 0.5199 - accuracy: 0.7837 - val_loss: 0.6394 - val_accuracy: 0.7694\n",
            "Epoch 13/35\n",
            "55/55 [==============================] - 12s 194ms/step - loss: 0.4939 - accuracy: 0.7962 - val_loss: 0.6126 - val_accuracy: 0.7717\n",
            "Epoch 14/35\n",
            "55/55 [==============================] - 9s 151ms/step - loss: 0.4810 - accuracy: 0.8082 - val_loss: 0.6859 - val_accuracy: 0.7329\n",
            "Epoch 15/35\n",
            "55/55 [==============================] - 12s 191ms/step - loss: 0.4724 - accuracy: 0.8059 - val_loss: 0.5711 - val_accuracy: 0.7740\n",
            "Epoch 16/35\n",
            "55/55 [==============================] - 11s 192ms/step - loss: 0.4712 - accuracy: 0.8014 - val_loss: 0.6294 - val_accuracy: 0.7717\n",
            "Epoch 17/35\n",
            "55/55 [==============================] - 9s 152ms/step - loss: 0.4691 - accuracy: 0.8162 - val_loss: 0.5463 - val_accuracy: 0.7900\n",
            "Epoch 18/35\n",
            "55/55 [==============================] - 12s 191ms/step - loss: 0.4049 - accuracy: 0.8339 - val_loss: 0.6025 - val_accuracy: 0.7648\n",
            "Epoch 19/35\n",
            "55/55 [==============================] - 9s 153ms/step - loss: 0.4065 - accuracy: 0.8373 - val_loss: 0.6041 - val_accuracy: 0.7694\n",
            "Epoch 20/35\n",
            "55/55 [==============================] - 12s 191ms/step - loss: 0.4052 - accuracy: 0.8299 - val_loss: 0.5757 - val_accuracy: 0.7785\n",
            "Epoch 21/35\n",
            "55/55 [==============================] - 12s 193ms/step - loss: 0.4081 - accuracy: 0.8333 - val_loss: 0.5578 - val_accuracy: 0.8014\n",
            "Epoch 22/35\n",
            "55/55 [==============================] - 11s 177ms/step - loss: 0.3915 - accuracy: 0.8413 - val_loss: 0.6105 - val_accuracy: 0.7671\n",
            "Epoch 23/35\n",
            "55/55 [==============================] - 11s 176ms/step - loss: 0.3580 - accuracy: 0.8613 - val_loss: 0.6110 - val_accuracy: 0.7717\n",
            "Epoch 24/35\n",
            "55/55 [==============================] - 12s 194ms/step - loss: 0.3137 - accuracy: 0.8756 - val_loss: 0.6136 - val_accuracy: 0.7785\n",
            "Epoch 25/35\n",
            "55/55 [==============================] - 10s 170ms/step - loss: 0.3611 - accuracy: 0.8533 - val_loss: 0.5813 - val_accuracy: 0.7945\n",
            "Epoch 26/35\n",
            "55/55 [==============================] - 12s 196ms/step - loss: 0.3342 - accuracy: 0.8721 - val_loss: 0.5681 - val_accuracy: 0.7991\n",
            "Epoch 27/35\n",
            "55/55 [==============================] - 13s 223ms/step - loss: 0.3185 - accuracy: 0.8687 - val_loss: 0.5896 - val_accuracy: 0.8059\n",
            "Epoch 28/35\n",
            "55/55 [==============================] - 10s 166ms/step - loss: 0.3114 - accuracy: 0.8716 - val_loss: 0.6189 - val_accuracy: 0.7763\n",
            "Epoch 29/35\n",
            "55/55 [==============================] - 13s 214ms/step - loss: 0.2920 - accuracy: 0.8893 - val_loss: 0.5775 - val_accuracy: 0.7968\n",
            "Epoch 30/35\n",
            "55/55 [==============================] - 11s 173ms/step - loss: 0.3044 - accuracy: 0.8813 - val_loss: 0.6832 - val_accuracy: 0.7808\n",
            "Epoch 31/35\n",
            "55/55 [==============================] - 11s 188ms/step - loss: 0.2763 - accuracy: 0.8916 - val_loss: 0.6051 - val_accuracy: 0.7808\n",
            "Epoch 32/35\n",
            "55/55 [==============================] - 10s 158ms/step - loss: 0.2790 - accuracy: 0.8858 - val_loss: 0.6016 - val_accuracy: 0.8014\n",
            "Epoch 33/35\n",
            "55/55 [==============================] - 11s 175ms/step - loss: 0.2693 - accuracy: 0.8995 - val_loss: 0.6659 - val_accuracy: 0.7877\n",
            "Epoch 34/35\n",
            "55/55 [==============================] - 10s 171ms/step - loss: 0.2631 - accuracy: 0.8955 - val_loss: 0.5947 - val_accuracy: 0.7877\n",
            "Epoch 35/35\n",
            "55/55 [==============================] - 12s 194ms/step - loss: 0.2306 - accuracy: 0.9075 - val_loss: 0.5992 - val_accuracy: 0.7831\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ad61595c250>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Entrenamiento del modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_dataset, validation_data=validation_dataset, epochs=35)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOGT8TEFpiqL",
        "outputId": "a763410f-2ec3-4db1-86ae-70ac457f38b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "La imagen es: roses\n",
            "Probabilidad: tf.Tensor(100.0, shape=(), dtype=float32) %\n"
          ]
        }
      ],
      "source": [
        "# Prueba de imagen\n",
        "image_path = \"/content/drive/MyDrive/ROSA-PRUEBA1.jpg\"\n",
        "img = keras.preprocessing.image.load_img(\n",
        "    image_path, target_size=(224, 224)\n",
        ")\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "# Imprimir la clase con mayor probabilidad y el porcentaje de probabilidad\n",
        "class_index = tf.argmax(score)\n",
        "class_name = class_names[class_index]\n",
        "probability = score[class_index] * 100\n",
        "\n",
        "print(\"La imagen es:\", class_name)\n",
        "print(\"Probabilidad:\", probability, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRkMmtzOUuEh",
        "outputId": "f9f84751-f18b-45e1-a6c6-348d4074b435"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save(\"modelo_entrenado.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sB10dQ9-WUDS"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/tattoo.keras')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
